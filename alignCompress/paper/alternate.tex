\documentclass[letterpaper,11pt,oneside]{article}
%\documentclass[a4paper,11pt,oneside]{article}


% J. Bioinformatics  see
%   http://www3.oup.co.uk/jnls/list/bioinformatics/instauth/
%   LATEX article style format, two-column text with 86mm columns
%   Figures either one-col (86mm) or double (178 mm) wide.
%   References must NOT be numbered,
%   listed in *alphabetical* order:
%   surname, initials, (year), paper title, journal, volume, pp. pages


\usepackage{multicol}

\usepackage{times}
\usepackage{epsfig}

\usepackage{verbatim}

\usepackage[none,bottom,dark,english]{draftcopy}
\draftcopyName{ DRAFT \number\day\/\number\month\/\number\year}

\usepackage[verbose]{geometry}
%\geometry{top=2cm,bottom=2cm,left=1.5cm,right=1.5cm,nohead}
\geometry{top=1in,bottom=1in,left=1in,right=1in,nohead}

\def\plotwidth{0.9\columnwidth}

%\setlength{\parindent}{0pt}
%\setlength{\parskip}{1.0ex plus0.5ex minus0.5ex}


\begin{document}

\title{ Modelling-Alignment for Sequences of Mixed or
of Medium to Low Information-Content }
% ?models don't shuffle?  ha, ha

\author{
  David R. Powell, Lloyd Allison and Trevor I. Dix \\
  Victorian Bioinformatics Consortium and \\
  School of Computer Science and Software Engineering, \\
  Monash University, \\
  Australia 3800.
}

\date{28 Oct 2002}
\maketitle

%-------------------------------------------------------------------------

%\toappear{Submitted to ? J. Bioinformatics ? 2002.}

\begin{abstract}

\noindent
Motivation:
Populations of biased, non-random sequences may cause standard alignment
algorithms to yield false-positive matches and false-negative misses.
A standard significance test based on the {\em shuffling} of
sequences is a partial solution, applicable to populations that can
be described by {\em simple} models.
Masking-out low information content intervals throws information away.
We describe a new and general method, {\em modelling-alignment}:
Population models are incorporated into the alignment process,
which can (and should) lead to changes in the rank-order of matches
between a query sequence and a collection of sequences,
compared to results from standard algorithms.
The new method is general and places very few conditions on
the nature of the models that can be used with it.
We apply modelling-alignment to local alignment, global alignment,
optimal alignment, and the relatedness problem.

\noindent
Results:
As expected, modelling-alignment and the standard {\tt prss} program from
the FASTA package have similar accuracy on sequence populations that
can be described by simple models, e.g. 0-order Markov models.
However, modelling-alignment has higher accuracy on populations
that are {\em mixed} or that are described by higher-order models:
It gives fewer false positives and false negatives as shown by
ROC curves and other results from tests on
% ??? real ???
real and artificial data.

\noindent
Availability:
The new software is available under Gnu GPL (copyleft).

\noindent
Contact:
powell@bruce.cs.monash.edu.au :-)

\noindent
Supplementary Information:
t.b.a..

\end{abstract}


%-------------------------------------------------------------------------
\section{Introduction} \label{sec:Intro}

Alignment algorithms are used to solve two quite different kinds of problem,
(i) are two (or more) sequences {\em related} or not, and
(ii) {\em how} are two (or more) sequences related,
{\em given} that they are related?
There is a ``fundamental difference between
the searching [for related sequences] and [optimal] alignment operations.''
-- Gribskov and Robinson~\cite{gribskov96}.
It is also well known that populations of biased, non-random,
low information content sequences may cause algorithms
to return false-positive matches and false-negative misses for
the first kind of problem and may also case poor alignments,
for the second kind of problem.
There are partial solutions, with disadvantages:
Masking-out~\cite{claverie93} low information content intervals
can reduce false-positives but it throws away some information and
raises the question of how low is low.
The significance of a possible match is often assessed by comparing
its score (or cost) with those obtained when ``one member of
the protein [say] pair [is] randomized"
(shuffled, permuted) -- Needleman and Wunsch~\cite{needleman70}.
We call this general kind of significance testing {\em shuffling};
note that an alignment is got under the assumption of random sequences
and {\em then} the shuffling test is applied, possibly to a bad alignment
if the sequences are non-random.

We describe a new method, {\em modelling-alignment} (M-alignment)
which incorporates explicit models of sequence populations.
It is based on the premise that two sequences are related if one tells
something {\em new} and {\em useful} about the other,
i.e. something not otherwise known.
It has a natural null-theory and hypothesis test.
Instead of a low information interval being masked-out, it is given
a low, but non-zero, weight thus not discarding information.
A high information interval, i.e. a {\em feature}, is given a high weight;
there is a big saving if it is matched in another sequence.
In general this can, and should, change the rank-order of alignments
between two sequences and the rank-order of matches between multiple sequences.
There is no hard (and arbitrary) threshhold for what is
a {\em background} low information interval or
for what is a high information feature;
there is a continuous spectrum of information content from low to high.
M-alignment is general and places few restrictions on the kind
of population model that can be used with it.
If the ``right'' model is not known in davance
there are some sensible candidates to try
and a good model can be detected on the basis of information content.
Algorithm time-complexity remains O(n**2) for reasonable models.
This paper extends work on the 1-state mutation model~\cite{allison99}
by applying M-alignment to
the relatedness and optimal alignment problems,
for both global and local alignment,
under the 3-state, linear gap-costs model \cite{gotoh82} of mutation.

M-alignment results are compared to those of
the {\tt prss} program~\cite{smith81} (from the FASTA package) which
is based on {\tt rdf2}~\cite{pearson88} with a shuffling significance test.
Receiver operating characteristics (ROC) curves show that, as expected,
both methods give similar results
on simple data, i.e. uniform and 0-order Markov model populations.
M-alignment is more accurate,
i.e. gives fewer false positives and fewer false negatives,
on mixed populations,
on populations of mixed sequences, and
on populations described by higher-order models.


%-------------------------------------------------------------------------
\section{Systems and Methods} \label{sec:sys}

\subsection{Models} \label{sec:models}
% non-random, compress'n, inf'n, seq' models, Markov m', Bayes, MML...

There is considerable interest in the compression of biological
sequences~\cite{grumbach94,lowenstern96,rivals97,allison00},
not so much to save disc space but
as a criterion for comparing models of populations of sequences.
The terms {\em biased}, {\em non-random}, {\em low information content}
and {\em compressible} are equivalent for our purposes:
If DNA bases, say, are generated uniformly at random, an optimal code
assigns each one a two-bit code.
This follows from
Shannon's mathematical theory of communication~\cite{shannon49}.
If the DNA comes from a biased 0-order model, say,
shorter codes can be allocated {\em on average}.
E.g. Probabilities of [1/2, 1/4, 1/8, 1/8] lead to codes of
[1, 2, 3, 3]-bits respectively, that is 1~3/4-bits on average.
For higher-order models, code-words depend on the {\em context}
of previous characters, on the `k' previous characters
for a Markov model of order~k.
Probabilistic finite-state automata (PFSAs),
also known as hidden Markov models,
have been used as models \cite{georgeff84} of populations of sequences.
Each of these models, and many others, can deliver a probabilistic
prediction for the next character in a sequence given a context.
From Shannon, the length of a code-word for the next character,
its {\em message length}, is the -log of this probability and
is a measure of the information content of the character in the context.
M-alignment uses this quantity.


\subsection{Relatedness and Alignment} \label{sec:rel}
% if v. how

The generic dynamic programming algorithm (DPA) for
sequence comparison can be used to find various kinds
of global alignments depending on how it is instantiated: E.g.
Given {\em scores} of one for a match and zero for mismatch, insert and delete,
the DPA finds the longest common subsequence (LCS).
Given {\em costs} of zero for a match and one for mismatch, insert and delete,
it finds an optimal alignment under the Levenshtein~\cite{levenshtein66}
metric also known as the simple edit-distance~\cite{sellers}.
{\em Linear} gap-costs, for runs of inserts or deletes,
are more plausible bioigically and Gotoh~\cite{gotoh82}
gave such an alignment algorithm; the key is to have three {\em states}
for each cell in the DPA's matrix, for costs (or scores)
{\em conditional} on diagonal, vertical and horizontal moves.

All of the above DPA variations find a global optimal alignment for
some criterion given, or at least under the assumption that,
two sequences are related.
Shuffling tries to solve the relatedness problem by comparing the
score (or cost) of an optimal alignment with the scores (costs)
of alignments of the randomized sequences.
If the former is not significantly better than the latter
the sequences are deemed to be unrelated.
The idea is that randomized sequences are {\em like} their originals in
general statistical terms but are otherwise unrelated.
Shuffling preserves 0-order statistics of sequences.
It can be arranged to preserve 1st-order statistics~\cite{fitch83}
and even codon usage~\cite{altschul85} but it is hard to imagine how
to carry it out while preserving the statistics of an arbitrary model
particularly if that is a mixture or is high-order.

A different approach to the relatedness problem
considers a probabilistic {\em mutation model}.
The costs (scores) of the DPA are replaced by the -log probabilities
of match, mismatch, insert and delete.
In fact costs and scores can be {\em normalized}~\cite{Allison93} to show
the underlying probabilities.
The DPA can then find a {\em most probable} alignment, but it can also
be modified to calculate the {\em joint} probability of two sequences:
An alignment is just a hypothesis.
The set of all alignments is exclusive and exhaustive, given that
two sequences are related.
Rather than selecting the largest probability,
their probabilities can therefore be {\em added}.
Bishop and Thompson~\cite{bishop86} did this for a 1-state mutation model.
Allison et al~\cite{Allison92} extended this to 3-state (linear gap-costs)
and 5-state (piece-wise linear gap-costs) mutation models,
and included the cost (complexity) of models so that simple
and complex models can be compared fairly.
Such considerations also give
a natural {\em null-theory} that the sequences are not related,
i.e. that one tells nothing new or useful about the other:
Two sequences are unrelated if
communicating them together yields no saving in terms
of compression over sending them separately.
The next section describes how these methods
are extended to local alignment and how the information
content of compressible sequences is taken into account in M-alignment


%-------------------------------------------------------------------------
\section{Algorithm} \label{sec:alg}

The M-alignment algorithms developed in this work
(i) make use of probabilistic alignment methods
for global and local alignment, and
(ii) incorporate sequence population models to calculate
the information content of characters in context.
This is done in combination with the 3-state, linear gap-cost mutation model.

Firstly,
probabilistic methods are used to estimate the probability of relatedness
of sequences S1 and S2 under {\em local alignment}, i.e. that there is some
configuration S1=A+L+B and S2=C+L'+D and that intervals L and L' are
related (globally) and that intervals A, B, C, and D, which are possibly empty,
are not related.
A, B, C and D are compressed with the population model.
L and L' are compressed with both the population and mutation models,
in a way to be described.
For the relatedness problem we {\em sum} over all such configurations,
that is over all A, L, B, C, L' and D and all alignments of L with L',
still in O(n**2)-time.
For the optimal local alignment problem we choose the best such configuration.

Secondly,
the DPA operates cell by cell on a two-dimensional array.
For linear gap-costs, each cell contains three values for the -log probability
of S1[1..i] and S2[1..j] conditional on the last operation
being a diagonal, vertical or horizontal move.
Each increment involves the -log probabilities of a mutation and
of a character from one or both strings as appropriate.
The key idea of M-alignment is to obtain the latter from a population model.


%-------------------------------------------------------------------------
\section{Implementation} \label{sec:impl}
% impl'n and tests

A version of the DPA was implemented to carry out M-alignment for
a 3-state, linear gap-costs mutation model, local alignment.
It accepts a population model as a parameter.
It is able to return either
the -log probability of two sequences being related
(by summing alignment probabilities) or
an optimal local alignment.

The program was tested on both real and artificial data.
Artificial data was generated by a process related to the
Metropolis algorithm~\cite{metropolis53}.
It is easy to generate a typical sequence given a population model.
The difficulty is to generate {\em related pairs} that are typical
of the population; uniform random mutations would cause
descendants to drift towards the statsitics of a uniform model.
The solution is to propose a mutation at random and to either accept it
or reject it.
Given a parent sequence, a mutation is proposed.
The mutated child is compressed with the population models.
If the model fits the child better than the parent the mutation is accepted;
for simple models a {\em local} calculation is sufficient.
If the model fits the child worse than the parent it may be accepted
probabilistically.
% NB. proposed or accepted ???
The process is continued until a certain number of mutations have been proposed.
Closely and distantly related pairs of sequences, L and L',
where L and L' are typical of the population model, can be created in this way.
For local alignment data,
unrelated prefixes A and C and suffixes B and D are generated from the model.

particular numbers, lengths and similarites of artifcial sequences...

%-------------------------------------------------------------------------
\section{Discussion} \label{sec:disc}

discuss ROC curves ...

and also at least one of total errors v. odds related ...

and real data ...

%-------------------------------------------------------------------------
\section{Conclusion} \label{sec:conc}


%-------------------------------------------------------------------------
\bibliographystyle{abbrv}

%\bibliographystyle{alpha}
%\small

\bibliography{biblio}

%\normalsize
\end{document}

